{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSAST for speech\n",
    "All functions copied from the following repo and then edited as indicated\n",
    "\n",
    "https://github.com/YuanGongND/ssast\n",
    "Additional authors: Matt, Daniela Wiepert\n",
    "\n",
    "Original ASTModel class was split into two - one for pretraining and one for finetuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, you will need access to google cloud storage bucket and the following packages must be installed on your system \n",
    "\n",
    "* albumentations (may run into issues in AIF)\n",
    "* librosa\n",
    "* torch, torchvision, torchaudio\n",
    "\n",
    "(can ignore the following if using AIF)\n",
    "* google-cloud\n",
    "* google-cloud-storage\n",
    "* google-cloud-bigquery\n",
    "\n",
    "If working on a local computer, you can run the following commands to gain access to the google storage bucket\n",
    "\n",
    "```gcloud auth application-default login```\n",
    "\n",
    "```gcloud auth application-defaul set-quota-project PROJECT_NAME```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "#built-in\n",
    "import argparse\n",
    "import ast\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from google.cloud import storage, bigquery\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "#local\n",
    "from dataloader_mayo import AudioDataset\n",
    "from models import ASTModel_pretrain, ASTModel_finetune\n",
    "from traintest_mayo import *\n",
    "from traintest_mask_mayo import *\n",
    "from utilities.dataloader_utils import collate_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "There are many mutable arguments when running SSAST. For normal purposes, only the dataloading, GCS, librosa vs. torchaudio, output, and fine-tuning parameters may need to be altered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "#data loading\n",
    "parser.add_argument('-i','--prefix',default='speech_ai/speech_lake/speech_poc_freeze_1', help='Input directory or location in google cloud storage bucket containing files to load')\n",
    "parser.add_argument('-d','--data_split_root', default='gs://ml-e107-phi-shared-aif-us-p/speech_ai/share/data_splits/amr_subject_dedup_594_train_100_test_binarized_v20220620', help='path to datasplit csvs. Assumes it points to a directory with a train.csv and test.csv')\n",
    "#GCS\n",
    "parser.add_argument('-b','--bucket_name', default='ml-e107-phi-shared-aif-us-p', help=\"google cloud storage bucket name\")\n",
    "parser.add_argument('-p','--project_name', default='ml-mps-aif-afdgpet01-p-6827', help='google cloud platform project name')\n",
    "#librosa vs torchaudio\n",
    "parser.add_argument('--lib', default=True, type=bool, help=\"Specify whether to load using librosa as compared to torch audio\")\n",
    "#output\n",
    "parser.add_argument('-o',\"--exp_dir\", type=str, default=\"/Users/m144443/Documents/mayo_ssast/experiments\", help=\"directory to dump experiments\")\n",
    "#Audio configuration parameters\n",
    "parser.add_argument(\"--dataset\", default='mayo',type=str, help=\"the dataset used for training\")\n",
    "parser.add_argument(\"--dataset_mean\", default=-4.2677393, type=float, help=\"the dataset mean, used for input normalization\")\n",
    "parser.add_argument(\"--dataset_std\", default=4.5689974, type=float, help=\"the dataset std, used for input normalization\")\n",
    "parser.add_argument(\"--target_length\", default=1024, type=int, help=\"the input length in frames\")\n",
    "parser.add_argument(\"--num_mel_bins\", default=128,type=int, help=\"number of input mel bins\")\n",
    "parser.add_argument(\"--resample_rate\", default=16000,type=int, help='resample rate for audio files')\n",
    "parser.add_argument(\"--reduce\", default=True, type=bool, help=\"Specify whether to reduce to monochannel\")\n",
    "parser.add_argument(\"--clip_length\", default=0, type=int, help=\"If truncating audio, specify clip length in # of frames. 0 = no truncation\")\n",
    "parser.add_argument(\"--tshift\", default=0, type=float, help=\"Specify p for time shift transformation\")\n",
    "parser.add_argument(\"--speed\", default=0, type=float, help=\"Specify p for speed tuning\")\n",
    "parser.add_argument(\"--gauss\", default=0, type=float, help=\"Specify p for adding gaussian noise\")\n",
    "parser.add_argument(\"--pshift\", default=0, type=float, help=\"Specify p for pitch shifting\")\n",
    "parser.add_argument(\"--pshiftn\", default=0, type=float, help=\"Specify number of steps for pitch shifting\")\n",
    "parser.add_argument(\"--gain\", default=0, type=float, help=\"Specify p for gain\")\n",
    "parser.add_argument(\"--stretch\", default=0, type=float, help=\"Specify p for audio stretching\")\n",
    "parser.add_argument('--freqm', help='frequency mask max length', type=int, default=0)\n",
    "parser.add_argument('--timem', help='time mask max length', type=int, default=0)\n",
    "parser.add_argument(\"--mixup\", type=float, default=0, help=\"how many (0-1) samples need to be mixup during training\")\n",
    "parser.add_argument(\"--noise\", type=bool, default=False, help=\"specify if augment noise in finetuning\")\n",
    "parser.add_argument(\"--skip_norm\", type=bool, default=False, help=\"specify whether to skip normalization on spectrogram\")\n",
    "#Model parameters\n",
    "parser.add_argument(\"--task\", type=str, default='ft_cls', help=\"pretraining or fine-tuning task\", choices=[\"ft_avgtok\", \"ft_cls\", \"pretrain_mpc\", \"pretrain_mpg\", \"pretrain_joint\"])\n",
    "parser.add_argument(\"--fstride\", type=int, default=128,help=\"soft split freq stride, overlap=patch_size-stride\")\n",
    "parser.add_argument(\"--tstride\", type=int, default=2, help=\"soft split time stride, overlap=patch_size-stride\")\n",
    "parser.add_argument(\"--fshape\", type=int, default=128,help=\"shape of patch on the frequency dimension\")\n",
    "parser.add_argument(\"--tshape\", type=int, default=2, help=\"shape of patch on the time dimension\")\n",
    "parser.add_argument('--model_size', default='base',help='the size of AST models', type=str)\n",
    "#Training parameters\n",
    "parser.add_argument('--batch_size', default=8, type=int, metavar='N', help='mini-batch size')\n",
    "parser.add_argument('--num_workers', default=0, type=int, metavar='NW', help='# of workers for dataloading (default: 32)')\n",
    "parser.add_argument(\"--epochs\", type=int, default=1, help=\"number of maximum training epochs\")\n",
    "parser.add_argument(\"--loss\", type=str, default=\"BCE\", help=\"the loss function for finetuning, depend on the task\", choices=[\"BCE\", \"CE\"])\n",
    "parser.add_argument(\"--optim\", type=str, default=\"adam\", help=\"training optimizer\", choices=[\"adamw\", \"adam\"])\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.001, type=float, metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--warmup', help='if use warmup learning rate scheduler', type=ast.literal_eval, default='True')\n",
    "parser.add_argument(\"--lr_patience\", type=int, default=1, help=\"how many epoch to wait to reduce lr if mAP doesn't improve\")\n",
    "parser.add_argument('--adaptschedule', help='if use adaptive scheduler ', type=ast.literal_eval, default='False')\n",
    "parser.add_argument(\"--n-print-steps\", type=int, default=100, help=\"number of steps to print statistics\")\n",
    "parser.add_argument('--save_model', help='save the models or not', type=ast.literal_eval, default='True')\n",
    "#fine-tuning parameters\n",
    "parser.add_argument(\"--pretrained_mdl_path\", type=str, help=\"the ssl pretrained models path\")#, default='/Users/m144443/Documents/mayo_ssast/pretrained_model/SSAST-Base-Frame-400.pth',) #/Users/m144443/Documents/mayo_ssast/pretrained_model/SSAST-Base-Frame-400.pth\n",
    "parser.add_argument(\"--freeze\",type=bool, default=True, help=\"Specify whether to freeze original model before fine-tuning\")\n",
    "parser.add_argument(\"--basic\", type=bool, default=True, help=\"run basic finetuning/metrics rather than altering lr or anything else\")\n",
    "parser.add_argument(\"--head_lr\", type=int, default=1, help=\"the factor of mlp-head_lr/lr, used in some fine-tuning experiments only\")\n",
    "parser.add_argument(\"--metrics\", type=str, default=\"mAP\", help=\"the main evaluation metrics for validation in finetuning\", choices=[\"mAP\", \"acc\"])\n",
    "parser.add_argument(\"--lrscheduler_start\", default=10, type=int, help=\"when to start decay in finetuning\")\n",
    "parser.add_argument(\"--lrscheduler_step\", default=5, type=int, help=\"the number of step to decrease the learning rate in finetuning\")\n",
    "parser.add_argument(\"--lrscheduler_decay\", default=0.5, type=float, help=\"the learning rate decay ratio in finetuning\")\n",
    "parser.add_argument(\"--wa\", help='if do weight averaging in finetuning', type=ast.literal_eval, default='False')\n",
    "parser.add_argument(\"--wa_start\", type=int, default=16, help=\"which epoch to start weight averaging in finetuning\")\n",
    "parser.add_argument(\"--wa_end\", type=int, default=30, help=\"which epoch to end weight averaging in finetuning\")\n",
    "#pretraining parameters\n",
    "parser.add_argument('--mask_patch', help='how many patches to mask (used only for ssl pretraining)', type=int, default=400)\n",
    "parser.add_argument(\"--cluster_factor\", type=int, default=3, help=\"mask clutering factor\")\n",
    "parser.add_argument(\"--epoch_iter\", type=int, default=2000, help=\"for pretraining, how many iterations to verify and save models\")\n",
    "#evaluation\n",
    "parser.add_argument('--eval_only', type=bool, default=False, help=\"specify if you want to only run evaluation - use pretrained_mdl_path to specify which model to load for evaluation\")\n",
    "parser.add_argument(\"--mdl_path\", type=str, default='/Users/m144443/Documents/mayo_ssast/experiments/models/audio_model.1.pth', help=\"if loading an already pre-trained/fine-tuned model\")\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment\n",
    "The first step is to make sure the GCS bucket is initialized if given a `bucket_name`. Additionally, the list of target labels must be set. \n",
    "\n",
    "In the original implementation, the list must be given as a `.txt` file to pass through the command line. In this implementation, we will set it as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCS set up\n",
    "if args.bucket_name is not None:\n",
    "    storage_client = storage.Client(project=args.project_name)\n",
    "    bq_client = bigquery.Client(project=args.project_name)\n",
    "    bucket = storage_client.bucket(args.bucket_name)\n",
    "else:\n",
    "    bucket = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target labels\n",
    "target_labels=['breathy',\n",
    "             'loudness decay',\n",
    "             'slow rate',\n",
    "             'high pitch',\n",
    "             'hoarse / harsh',\n",
    "             'irregular artic breakdowns',\n",
    "             'rapid rate',\n",
    "             'reduced OA loudness',\n",
    "             'abn pitch variability',\n",
    "             'strained',\n",
    "             'hypernasal',\n",
    "             'abn loudness variability',\n",
    "              'distortions']\n",
    "#set number of target classes for classification\n",
    "args.n_class = len(target_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "The data must be loaded in steps, starting by loading in the label data, then setting up audio configurations for training and evaluation, then generating AudioDataset objects, and finally setting up the dataloaders.\n",
    "\n",
    "When loading data, we start with a data split root, which we expect to be a directory containing a `train.csv` file and `test.csv` file with file names for train/test and the associated label data.\n",
    "\n",
    "The audio configurations are dictionaries with parameters for altering the audio and generating spectrograms.\n",
    "\n",
    "The AudioDatasets are set up in the `dataloader_mayo.py` script, using transforms specified in `utilities/dataloader_utils.py`. \n",
    "\n",
    "Finally, the dataloaders take in the datasets and batch size + number of workers.\n",
    "\n",
    "Please note that the resulting samples will be a dictionary with the keys `uid`, `fbank`, `waveform`, `targets`, `sample_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_split_root):\n",
    "    '''\n",
    "    This function assumes data loading based on previous notebooks - if anything changes with the \n",
    "    CSVs or columns need to be altered differently, this is the function to change\n",
    "    '''\n",
    "    #Note: assumes that the data split root is a path to a folder containing a train.csv and test.csv \n",
    "    train_path = f'{data_split_root}/train.csv'\n",
    "    test_path = f'{data_split_root}/test.csv'\n",
    "    \n",
    "    # (1) load the train and test files to a df (requires a 'uid' column)\n",
    "    train_df = pd.read_csv(train_path, index_col = 'uid')\n",
    "    test_df = pd.read_csv(test_path, index_col = 'uid')\n",
    "\n",
    "    #(2) alter data columns\n",
    "    train_df[\"distortions\"]=((train_df[\"distorted Cs\"]+train_df[\"distorted V\"])>0).astype(int)\n",
    "    test_df[\"distortions\"]=((test_df[\"distorted Cs\"]+test_df[\"distorted V\"])>0).astype(int)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Load data, note that we are not doing any validation\n",
    "train_df, test_df = load_data(args.data_split_root)\n",
    "\n",
    "#(2) set audio configurations (again, no val_loader because no validation set)\n",
    "train_audio_conf = {'dataset': args.dataset, 'mode': 'train', 'resample_rate': args.resample_rate, 'reduce': args.reduce, 'clip_length': args.clip_length,\n",
    "                'tshift':args.tshift, 'speed':args.speed, 'gauss_noise':args.gauss, 'pshift':args.pshift, 'pshiftn':args.pshiftn, 'gain':args.gain, 'stretch': args.stretch,\n",
    "                'num_mel_bins': args.num_mel_bins, 'target_length': args.target_length, 'freqm': args.freqm, 'timem': args.timem, 'mixup': args.mixup, 'noise':args.noise,\n",
    "                'mean':args.dataset_mean, 'std':args.dataset_std, 'skip_norm':args.skip_norm}\n",
    "\n",
    "eval_audio_conf = {'dataset': args.dataset, 'mode': 'evaluation', 'resample_rate': args.resample_rate, 'reduce': args.reduce, 'clip_length': args.clip_length,\n",
    "                'tshift':args.tshift, 'speed':args.speed, 'gauss_noise':args.gauss, 'pshift':args.pshift, 'pshiftn':args.pshiftn, 'gain':args.gain, 'stretch': args.stretch,\n",
    "                'num_mel_bins': args.num_mel_bins, 'target_length': args.target_length, 'freqm': args.freqm, 'timem': args.timem, 'mixup': args.mixup, 'noise':args.noise,\n",
    "                'mean':args.dataset_mean, 'std':args.dataset_std, 'skip_norm':args.skip_norm}\n",
    "\n",
    "#(3) Generate audio dataset, note that if bucket not given, it assumes None and loads from local files\n",
    "train_dataset = AudioDataset(annotations_df=train_df, target_labels=target_labels, audio_conf=train_audio_conf, \n",
    "                                prefix=args.prefix, bucket=bucket, librosa=args.lib) #librosa = True (might need to debug this one)\n",
    "eval_dataset = AudioDataset(annotations_df=test_df, target_labels=target_labels, audio_conf=eval_audio_conf, \n",
    "                            prefix=args.prefix, bucket=bucket, librosa=args.lib)\n",
    "\n",
    "#(4) set up data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=False, drop_last=True, collate_fn=collate_fn)\n",
    "eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, pin_memory=True, collate_fn=collate_fn)\n",
    "\n",
    "print('Now train with {:s} with {:d} training samples, evaluate with {:d} samples'.format(args.dataset, len(train_loader.dataset), len(eval_loader.dataset)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrograms\n",
    "We can now visualize a spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a spectrogram\n",
    "sample = train_loader.dataset[1]\n",
    "spectrogram = sample['fbank']\n",
    "label = sample['targets']\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(num=1, figsize=(15, 15), dpi=80)\n",
    "plt.imshow(spectrogram.transpose(1,0).flip(0))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "We only have fine-tuning functionality, so we initialize an ASTModel_finetune object using our arguments. We further freeze the original model if the `args.freeze` parameter has been set to True (which is default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5) set up model based on specified task\n",
    "assert (args.task == 'ft_cls' or args.task == 'ft_avgtok'), f'Unrecognized task ({args.task}) given.'\n",
    "\n",
    "ast_mdl = ASTModel_finetune(task=args.task, label_dim=args.n_class, \n",
    "                                fshape=args.fshape, tshape=args.tshape, \n",
    "                                fstride=args.fstride, tstride=args.tstride,\n",
    "                                input_fdim=args.num_mel_bins, input_tdim=args.target_length, \n",
    "                                model_size=args.model_size, load_pretrained_mdl_path=args.pretrained_mdl_path)\n",
    "\n",
    "if args.freeze:\n",
    "    #FREEZE THE MODEL (only finetuning classifier head)\n",
    "    for param in ast_mdl.v.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    model_parameters = filter(lambda p: p.requires_grad, ast_mdl.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(f'Number of trainable parameters: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(6) set up save directory\n",
    "print(\"\\nCreating experiment directory: %s\" % args.exp_dir)\n",
    "if not os.path.exists(args.exp_dir):\n",
    "    os.makedirs(args.exp_dir)\n",
    "with open(\"%s/args.pkl\" % args.exp_dir, \"wb\") as f:\n",
    "    pickle.dump(args, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning vs. Evaluation Only\n",
    "\n",
    "This implementation has the option to fine-tune a model, but also to only run evaluation using the test dataset. If `args.eval_only` is False, fine-tuning will proceed as normal. Otherwise, a specified model will be loaded.\n",
    "\n",
    "Additionally, there are different fine-tuning strategies available. The first is a basic finetuning and evaluation loop, which can be selected by setting `args.basic` to True. The second is a more complex loop with lr scheduling that takes functions from `traintest_mayo.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUNNING BASIC FUNCTIONS\n",
    "\n",
    "def basic_finetune(args, ast_mdl, train_loader):\n",
    "    '''\n",
    "    Run simple fine-tuning - BCE loss, AdamW optimizer - basic training loop\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ast_mdl.to(device)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    #does not change anything about learning rates and what not\n",
    "    optim = torch.optim.AdamW([p for p in ast_mdl.parameters() if p.requires_grad])\n",
    "\n",
    "    ast_mdl.train()\n",
    "    for e in range(args.epochs):\n",
    "        running_loss = 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            x = batch['fbank']\n",
    "            x = x.to(device)\n",
    "            targets = batch['targets'] #have to change to select targets like this\n",
    "            targets = targets.to(device)\n",
    "            optim.zero_grad()\n",
    "            o =  ast_mdl(x) #no need for task + give just fbank\n",
    "            loss = criterion(o, targets)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running_loss += loss.item()\n",
    "            print(f'Progress: {round(i/len(train_loader)*100)}%    ',end='\\r')\n",
    "            \n",
    "        print(e, running_loss/len(train_loader))\n",
    "\n",
    "    outname = \"_\".join(['ast_mdl',args.model_size, args.dataset, str(args.n_class), args.optim, str(args.epochs)+'epoch'])+'.pt'\n",
    "    outpath = os.path.join(args.exp_dir,outname)\n",
    "    torch.save(ast_mdl.state_dict(), outpath)\n",
    "    return ast_mdl\n",
    "\n",
    "def basic_eval(ast_mdl, eval_loader):\n",
    "    '''\n",
    "    basic evaluation loop\n",
    "    '''\n",
    "    #does not change anything about learning rates and what not\n",
    "    optim = torch.optim.AdamW([p for p in ast_mdl.parameters() if p.requires_grad])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ast_mdl.to_device()\n",
    "    ast_mdl.eval()\n",
    "    all_preds=[]\n",
    "    all_targets=[]\n",
    "    for i, batch in enumerate(eval_loader):\n",
    "        x = batch['fbank']\n",
    "        x = x.to(device)\n",
    "        targets = batch['targets']\n",
    "        targets = targets.to(device)\n",
    "        optim.zero_grad()\n",
    "        o=ast_mdl(x)\n",
    "        all_preds.append(o)\n",
    "        all_targets.append(targets)\n",
    "        print(f'Progress: {round(i/len(eval_loader)*100)}%    ',end='\\r')\n",
    "    \n",
    "    return all_preds, all_targets    \n",
    "\n",
    "def basic_metrics(preds, targets, target_labels, args):\n",
    "    '''\n",
    "    Get simple metrics: only returns AUC for each label\n",
    "    '''\n",
    "    pred_mat=torch.sigmoid(torch.cat(preds)).cpu().detach().numpy()\n",
    "    target_mat=torch.cat(targets).cpu().detach().numpy()\n",
    "    aucs=roc_auc_score(target_mat, pred_mat, average = None)\n",
    "    print(aucs)\n",
    "    data = [\n",
    "    ('Label', target_labels),\n",
    "    ('AUC', target_labels)]\n",
    "    data = pd.DataFrame({'Label':target_labels, 'AUC':aucs})\n",
    "    data.to_csv(os.path.join(args.exp_dir, 'basic_metrics.csv'), index=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINE-TUNING LOOPS\n",
    "if not args.eval_only:\n",
    "    #(7) Run models\n",
    "    print('Now starting fine-tuning for {:d} epochs'.format(args.epochs))\n",
    "    #rather than the entire lr scheduler process, you can choose to run a simple finetuning method + get AUCsjft\n",
    "    if args.basic:\n",
    "        ast_mdl = basic_finetune(args, ast_mdl, train_loader)\n",
    "    else:\n",
    "        ast_mdl = train(args=args, audio_model=ast_mdl, train_loader=train_loader, val_loader=None)\n",
    "\n",
    "else: #RUN ONLY EVALUATION\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    sd = torch.load(args.mdl_path, map_location=device)\n",
    "    ast_mdl.load_state_dict(sd, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(8) evaluation:\n",
    "if args.basic:\n",
    "    preds, targets = basic_eval(ast_mdl, eval_loader)\n",
    "    metrics = basic_metrics(preds, targets, target_labels, args)\n",
    "else:\n",
    "    evaluation(args=args, audio_model=ast_mdl, eval_loader=eval_loader, val_loader=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize AUC curves\n",
    "This hasn't been tested yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.basic:\n",
    "    for i in range(len(metrics[1])):\n",
    "        fpr, tpr, _ = roc_curve(metrics[2][:,i],  metrics[1][:,i])\n",
    "        plt.plot(fpr,tpr,label=metrics[0]['Label'][i]+\", auc=\"+str(round(metrics[0]['AUC'][i],3)))\n",
    "        plt.legend(loc=4)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
