{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSAST for speech\n",
    "All functions copied from the following repo and then edited as indicated\n",
    "\n",
    "https://github.com/YuanGongND/ssast\n",
    "Additional authors: Matt, Daniela Wiepert\n",
    "\n",
    "Original ASTModel class was split into two - one for pretraining and one for finetuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment must include the following packages, all of which can be dowloaded with pip or conda:\n",
    "* albumentations\n",
    "* librosa\n",
    "* torch, torchvision, torchaudio\n",
    "* tqdm (this is essentially enumerate(dataloader) except it prints out a nice progress bar for you)\n",
    "* pyarrow\n",
    "\n",
    "If running on your local machine and not in a GCP environment, you will also need to install:\n",
    "* google-cloud-storage\n",
    "\n",
    "The [requirements.txt](https://github.com/dwiepert/mayo-ssast/blob/main/requirements.txt) can be used to set up this environment. \n",
    "\n",
    "To access data stored in GCS on your local machine, you will need to additionally run\n",
    "\n",
    "```gcloud auth application-default login```\n",
    "\n",
    "```gcloud auth application-defaul set-quota-project PROJECT_NAME```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORTS\n",
    "#built-in\n",
    "import argparse\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pyarrow\n",
    "\n",
    "from google.cloud import storage, bigquery\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "#local\n",
    "from dataloader_mayo import AudioDataset\n",
    "from models import ASTModel_pretrain, ASTModel_finetune\n",
    "from old_files.traintest_mayo import *\n",
    "from traintest_mask_mayo import *\n",
    "from utilities import collate_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCS loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(gcs_path,outpath, bucket):\n",
    "    '''\n",
    "    Download a model from google cloud storage and the args.pkl file located in the same folder(if it exists)\n",
    "\n",
    "    Inputs:\n",
    "    :param gcs_path: full file path in the bucket to a pytorch model(no gs://project-name in the path)\n",
    "    :param outpath: string path to directory where you want the model to be stored\n",
    "    :param bucket: initialized GCS bucket object\n",
    "    Outputs:\n",
    "    :return mdl_path: a string path to the local version of the finetuned model (args.pkl will be in the same folder as this model)\n",
    "    '''\n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "\n",
    "    dir_path = os.path.dirname(gcs_path)\n",
    "    bn = os.path.basename(gcs_path)\n",
    "    blobs = bucket.list_blobs(prefix=dir_path)\n",
    "    mdl_path = ''\n",
    "    for blob in blobs:\n",
    "        blob_bn = os.path.basename(blob.name)\n",
    "        if blob_bn == bn:\n",
    "            destination_uri = '{}/{}'.format(outpath, blob_bn) #download model \n",
    "            mdl_path = destination_uri\n",
    "        elif blob_bn == 'args.pkl':\n",
    "            destination_uri = '{}/model_args.pkl'.format(outpath) #download args.pkl as model_args.pkl\n",
    "        else:\n",
    "            continue #skip any other files\n",
    "        if not os.path.exists(destination_uri):\n",
    "            blob.download_to_filename(destination_uri)\n",
    "   \n",
    "    return mdl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload(gcs_prefix, path, bucket):\n",
    "    '''\n",
    "    Upload a file to a google cloud storage bucket\n",
    "    Inputs:\n",
    "    :param gcs_dir: directory path in the bucket to save file to (no gs://project-name in the path)\n",
    "    :param path: local string path of the file to upload\n",
    "    :param bucket: initialized GCS bucket object\n",
    "    '''\n",
    "    assert bucket is not None, 'no bucket given for uploading'\n",
    "    if gcs_prefix is None:\n",
    "        gcs_prefix = os.path.dirname(path)\n",
    "    blob = bucket.blob(os.path.join(gcs_prefix, os.path.basename(path)))\n",
    "    blob.upload_from_filename(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading functions\n",
    "for loading in old model arguments and loading in annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_args(args):\n",
    "    '''\n",
    "    Load in an .pkl file of args\n",
    "    :param args: dict with all the argument values\n",
    "    :return model_args: dict with all the argument values from the finetuned model\n",
    "    '''\n",
    "    # assumes that the model is saved in the same folder as an args.pkl file \n",
    "    folder = os.path.basename(os.path.dirname(args.finetuned_mdl_path))\n",
    "\n",
    "    if os.path.exists(os.path.join(folder, 'model_args.pkl')): #if downloaded from gcs into the exp dir, it should be saved under mdl_args.pkl to make sure it doesn't overwrite the args.pkl\n",
    "        with open(os.path.join(folder, 'model_args.pkl'), 'rb') as f:\n",
    "            model_args = pickle.load(f)\n",
    "    elif os.path.exists(os.path.join(folder, 'args.pkl')): #if not downloaded and instead stored in a local place, it will be saved as args.pkl\n",
    "        with open(os.path.join(folder, 'args.pkl'), 'rb') as f:\n",
    "            model_args = pickle.load(f)\n",
    "    else: #if there are no saved args\n",
    "        print('No args.pkl or model_args.pkl stored with the finetuned model. Using the current args for initializing the finetuned model instead.')\n",
    "        model_args = args\n",
    "    \n",
    "    return model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mdl_args(args):\n",
    "    '''\n",
    "    Get model args used during finetuning of the specified model\n",
    "    :param args: dict with all the argument values\n",
    "    :return model_args: dict with all the argument values from the finetuned model\n",
    "    :return finetuned_mdl_path: updated finetuned_mdl_path (in case it needed to be downloaded from gcs)\n",
    "    '''\n",
    "    #if running a pretrained model only, use the args from this run\n",
    "    if args.finetuned_mdl_path is None:\n",
    "        model_args = args\n",
    "    else:\n",
    "    #if running a finetuned model\n",
    "        #(1): check if saved on cloud and load the model and args.pkl\n",
    "        if args.finetuned_mdl_path[:5] =='gs://':\n",
    "                mdl_path = args.finetuned_mdl_path[5:].replace(args.bucket_name,'')[1:]\n",
    "                args.finetuned_mdl_path = download_model(mdl_path, args.exp_dir, args.bucket)\n",
    "        \n",
    "        #(2): load the args used for finetuning\n",
    "        model_args = load_args(args)\n",
    "\n",
    "        #(3): check if the checkpoint for the finetuned model is downloaded\n",
    "        if model_args.pretrained_mdl_path[:5] =='gs://': #if checkpoint on cloud\n",
    "            checkpoint = model_args.pretrained_mdl_path[5:].replace(model_args.bucket_name,'')[1:]\n",
    "            if model_args.bucket_name != args.bucket_name: #if the bucket is not the same as the current bucket, initialize the bucket for downloading\n",
    "                if args.bucket_name is not None:\n",
    "                    storage_client = storage.Client(project=model_args.project_name)\n",
    "                    model_args.bucket = storage_client.bucket(model_args.bucket_name)\n",
    "                else:\n",
    "                    model_args.bucket = None\n",
    "\n",
    "                checkpoint = download_model(checkpoint, model_args.bucket) #download with the new bucket\n",
    "            else:\n",
    "                checkpoint = download_model(checkpoint, args.bucket) #download with the current bucket\n",
    "            model_args.pretrained_mdl_path = checkpoint #reset the checkpoint path\n",
    "        else: #load in from local machine, just need to check that the path exists\n",
    "            assert os.path.exists(model_args.pretrained_mdl_path), f'Current pretrain checkpoint does not exist on local machine: {model_args.pretrained_mdl_path}'\n",
    "\n",
    "    return model_args, args.finetuned_mdl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_split_root, exp_dir, cloud, cloud_dir, bucket):\n",
    "    \"\"\"\n",
    "    Load the train and test data from a directory. Assumes the train and test data will exist in this directory under train.csv and test.csv\n",
    "    :param data_split_root: specify str path where datasplit csvs are located\n",
    "    :param exp_dir: specify LOCAL output directory as str\n",
    "    :param cloud: boolean to specify whether to save everything to google cloud storage\n",
    "    :param cloud_dir: if saving to the cloud, you can specify a specific place to save to in the CLOUD bucket\n",
    "    :param bucket: google cloud storage bucket object\n",
    "    :return train_df, val_df, test_df: loaded dataframes with annotations\n",
    "    \"\"\"\n",
    "    train_path = f'{data_split_root}/train.csv'\n",
    "    test_path = f'{data_split_root}/test.csv'\n",
    "    #get data\n",
    "    train_df = pd.read_csv(train_path, index_col = 'uid')\n",
    "    test_df = pd.read_csv(test_path, index_col = 'uid')\n",
    "\n",
    "    #randomly sample to get validation set \n",
    "    val_df = train_df.sample(50)\n",
    "    train_df = train_df.drop(val_df.index)\n",
    "\n",
    "    #save validation set\n",
    "    val_path = os.path.join(exp_dir, 'validation.csv')\n",
    "    val_df.to_csv(val_path, index=True)\n",
    "\n",
    "    if cloud:\n",
    "        upload(cloud_dir, val_path, bucket)\n",
    "\n",
    "    #alter data columns\n",
    "    train_df[\"distortions\"]=((train_df[\"distorted Cs\"]+train_df[\"distorted V\"])>0).astype(int)\n",
    "    val_df[\"distortions\"]=((val_df[\"distorted Cs\"]+val_df[\"distorted V\"])>0).astype(int)\n",
    "    test_df[\"distortions\"]=((test_df[\"distorted Cs\"]+test_df[\"distorted V\"])>0).astype(int)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "There are many mutable arguments when running SSAST. See the README for more info on the most important arguments to alter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "#Inputs\n",
    "parser.add_argument('-i','--prefix',default='speech_ai/speech_lake/', help='Input directory or location in google cloud storage bucket containing files to load')\n",
    "parser.add_argument(\"-s\", \"--study\", choices = ['r01_prelim','speech_poc_freeze_1', None], default='speech_poc_freeze_1', help=\"specify study name\")\n",
    "parser.add_argument(\"-d\", \"--data_split_root\", default='gs://ml-e107-phi-shared-aif-us-p/speech_ai/share/data_splits/amr_subject_dedup_594_train_100_test_binarized_v20220620/test.csv', help=\"specify file path where datasplit is located. If you give a full file path to classification, an error will be thrown. On the other hand, evaluation and embedding expects a single .csv file.\")\n",
    "parser.add_argument('-l','--label_txt', default='/Users/m144443/Documents/GitHub/mayo-ssast/src/labels.txt')\n",
    "parser.add_argument('--lib', default=False, type=bool, help=\"Specify whether to load using librosa as compared to torch audio\")\n",
    "#GCS\n",
    "parser.add_argument('-b','--bucket_name', default='ml-e107-phi-shared-aif-us-p', help=\"google cloud storage bucket name\")\n",
    "parser.add_argument('-p','--project_name', default='ml-mps-aif-afdgpet01-p-6827', help='google cloud platform project name')\n",
    "parser.add_argument('--cloud', default=False, type=bool, help=\"Specify whether to save everything to cloud\")\n",
    "#output\n",
    "parser.add_argument(\"--dataset\", default=None,type=str, help=\"When saving, the dataset arg is used to set file names. If you do not specify, it will assume the lowest directory from data_split_root\")\n",
    "parser.add_argument(\"-o\", \"--exp_dir\", default=\"./experiments2\", help='specify LOCAL output directory')\n",
    "parser.add_argument('--cloud_dir', default='m144443/temp_out/ssast2', type=str, help=\"if saving to the cloud, you can specify a specific place to save to in the CLOUD bucket\")\n",
    "#Mode specific\n",
    "parser.add_argument(\"-m\", \"--mode\", choices=['train','eval','extraction'], default='extraction')\n",
    "parser.add_argument(\"--finetuned_mdl_path\", type=str, default='/Users/m144443/Documents/GitHub/mayo-ssast/experiments2/amr_subject_dedup_594_train_100_test_binarized_v20220620_base_13_adam_epoch1_ast_mdl.pt', help=\"if loading an already pre-trained/fine-tuned model\")\n",
    "parser.add_argument(\"--pretrained_mdl_path\", type=str, default='/Users/m144443/Documents/mayo_ssast/pretrained_model/SSAST-Base-Frame-400.pth', help=\"the ssl pretrained models path\")#, default='/Users/m144443/Documents/mayo_ssast/pretrained_model/SSAST-Base-Frame-400.pth',) #/Users/m144443/Documents/mayo_ssast/pretrained_model/SSAST-Base-Frame-400.pth\n",
    "parser.add_argument(\"--freeze\",type=bool, default=True, help=\"Specify whether to freeze original model before fine-tuning\")\n",
    "parser.add_argument('--original_fn', type=bool, default=False, help=\"specify whether to use the original SSAST functions\")\n",
    "parser.add_argument('--embedding_type', type=str, default='pt', help='specify whether embeddings should be extracted from classification head (ft) or base pretrained model (pt)', choices=['ft','pt'])\n",
    "#Audio configuration parameters\n",
    "parser.add_argument(\"--dataset_mean\", default=-4.2677393, type=float, help=\"the dataset mean, used for input normalization\")\n",
    "parser.add_argument(\"--dataset_std\", default=4.5689974, type=float, help=\"the dataset std, used for input normalization\")\n",
    "parser.add_argument(\"--target_length\", default=1024, type=int, help=\"the input length in frames\")\n",
    "parser.add_argument(\"--num_mel_bins\", default=128,type=int, help=\"number of input mel bins\")\n",
    "parser.add_argument(\"--resample_rate\", default=16000,type=int, help='resample rate for audio files')\n",
    "parser.add_argument(\"--reduce\", default=True, type=bool, help=\"Specify whether to reduce to monochannel\")\n",
    "parser.add_argument(\"--clip_length\", default=0, type=int, help=\"If truncating audio, specify clip length in # of frames. 0 = no truncation\")\n",
    "parser.add_argument(\"--tshift\", default=0, type=float, help=\"Specify p for time shift transformation\")\n",
    "parser.add_argument(\"--speed\", default=0, type=float, help=\"Specify p for speed tuning\")\n",
    "parser.add_argument(\"--gauss\", default=0, type=float, help=\"Specify p for adding gaussian noise\")\n",
    "parser.add_argument(\"--pshift\", default=0, type=float, help=\"Specify p for pitch shifting\")\n",
    "parser.add_argument(\"--pshiftn\", default=0, type=float, help=\"Specify number of steps for pitch shifting\")\n",
    "parser.add_argument(\"--gain\", default=0, type=float, help=\"Specify p for gain\")\n",
    "parser.add_argument(\"--stretch\", default=0, type=float, help=\"Specify p for audio stretching\")\n",
    "parser.add_argument('--freqm', help='frequency mask max length', type=int, default=0)\n",
    "parser.add_argument('--timem', help='time mask max length', type=int, default=0)\n",
    "parser.add_argument(\"--mixup\", type=float, default=0, help=\"how many (0-1) samples need to be mixup during training\")\n",
    "parser.add_argument(\"--noise\", type=bool, default=False, help=\"specify if augment noise in finetuning\")\n",
    "parser.add_argument(\"--skip_norm\", type=bool, default=False, help=\"specify whether to skip normalization on spectrogram\")\n",
    "#Model parameters\n",
    "parser.add_argument(\"--task\", type=str, default='ft_cls', help=\"pretraining or fine-tuning task\", choices=[\"ft_avgtok\", \"ft_cls\", \"pretrain_mpc\", \"pretrain_mpg\", \"pretrain_joint\"])\n",
    "parser.add_argument(\"--fstride\", type=int, default=128,help=\"soft split freq stride, overlap=patch_size-stride\")\n",
    "parser.add_argument(\"--tstride\", type=int, default=2, help=\"soft split time stride, overlap=patch_size-stride\")\n",
    "parser.add_argument(\"--fshape\", type=int, default=128,help=\"shape of patch on the frequency dimension\")\n",
    "parser.add_argument(\"--tshape\", type=int, default=2, help=\"shape of patch on the time dimension\")\n",
    "parser.add_argument('--model_size', default='base',help='the size of AST models', type=str)\n",
    "parser.add_argument(\"-pm\", \"--pooling_mode\", default=\"mean\", help=\"specify method of pooling last hidden layer\", choices=['mean','sum','max'])\n",
    "#Training parameters\n",
    "parser.add_argument('--batch_size', default=1, type=int, metavar='N', help='mini-batch size')\n",
    "parser.add_argument('--num_workers', default=0, type=int, metavar='NW', help='# of workers for dataloading (default: 32)')\n",
    "parser.add_argument(\"--epochs\", type=int, default=1, help=\"number of maximum training epochs\")\n",
    "parser.add_argument(\"--loss\", type=str, default=\"BCE\", help=\"the loss function for finetuning, depend on the task\", choices=[\"BCE\", \"CE\"])\n",
    "parser.add_argument(\"--optim\", type=str, default=\"adam\", help=\"training optimizer\", choices=[\"adamw\", \"adam\"])\n",
    "parser.add_argument('-lr', '--learning_rate', default=0.001, type=float, metavar='LR', help='initial learning rate')\n",
    "parser.add_argument(\"--scheduler\", type=str, default=None, help=\"specify lr scheduler\", choices=[\"onecycle\", None])\n",
    "parser.add_argument(\"--max_lr\", type=float, default=0.01, help=\"specify max lr for lr scheduler\")\n",
    "#training parameters, original fn\n",
    "parser.add_argument('--warmup', help='if use warmup learning rate scheduler', type=ast.literal_eval, default='False')\n",
    "parser.add_argument(\"--lr_patience\", type=int, default=1, help=\"how many epoch to wait to reduce lr if mAP doesn't improve\")\n",
    "parser.add_argument('--adaptschedule', help='if use adaptive scheduler ', type=ast.literal_eval, default='False')\n",
    "parser.add_argument(\"--n-print-steps\", type=int, default=100, help=\"number of steps to print statistics\")\n",
    "parser.add_argument('--save_model', help='save the models or not', type=ast.literal_eval, default='True')\n",
    "parser.add_argument(\"--head_lr\", type=int, default=1, help=\"the factor of mlp-head_lr/lr, used in some fine-tuning experiments only\")\n",
    "#original finetuning\n",
    "parser.add_argument(\"--lrscheduler_start\", default=10, type=int, help=\"when to start decay in finetuning\")\n",
    "parser.add_argument(\"--lrscheduler_step\", default=5, type=int, help=\"the number of step to decrease the learning rate in finetuning\")\n",
    "parser.add_argument(\"--lrscheduler_decay\", default=0.5, type=float, help=\"the learning rate decay ratio in finetuning\")\n",
    "parser.add_argument(\"--wa\", help='if do weight averaging in finetuning', type=ast.literal_eval, default='False')\n",
    "parser.add_argument(\"--wa_start\", type=int, default=16, help=\"which epoch to start weight averaging in finetuning\")\n",
    "parser.add_argument(\"--wa_end\", type=int, default=30, help=\"which epoch to end weight averaging in finetuning\")\n",
    "parser.add_argument(\"--metrics\", type=str, default=\"mAP\", help=\"the main evaluation metrics for validation in finetuning\", choices=[\"mAP\", \"acc\"])\n",
    "#original pretraining\n",
    "parser.add_argument('--mask_patch', help='how many patches to mask (used only for ssl pretraining)', type=int, default=400)\n",
    "parser.add_argument(\"--cluster_factor\", type=int, default=3, help=\"mask clutering factor\")\n",
    "parser.add_argument(\"--epoch_iter\", type=int, default=2000, help=\"for pretraining, how many iterations to verify and save models\")\n",
    "#OTHER\n",
    "parser.add_argument(\"--debug\", default=True, type=bool)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment\n",
    "The first step is to make sure the GCS bucket is initialized if given a `bucket_name`. Additionally, the list of target labels must be set. \n",
    "\n",
    "In the original implementation, the list must be given as a `.txt` file to pass through the command line. In this implementation, we will set it as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCS set up\n",
    "if args.bucket_name is not None:\n",
    "    storage_client = storage.Client(project=args.project_name)\n",
    "    bq_client = bigquery.Client(project=args.project_name)\n",
    "    bucket = storage_client.bucket(args.bucket_name)\n",
    "else:\n",
    "    bucket = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2), check if given study or if the prefix is the full prefix.\n",
    "if args.study is not None:\n",
    "    args.prefix = os.path.join(args.prefix, args.study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # (3) get dataset name\n",
    "if args.dataset is None:\n",
    "    if '.csv' in args.data_split_root:\n",
    "        args.dataset = '{}_{}'.format(os.path.basename(os.path.dirname(args.data_split_root)), os.path.basename(args.data_split_root[:-4]))\n",
    "    else:\n",
    "        args.dataset = os.path.basename(args.data_split_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target labels\n",
    "args.target_labels=['breathy',\n",
    "             'loudness decay',\n",
    "             'slow rate',\n",
    "             'high pitch',\n",
    "             'hoarse / harsh',\n",
    "             'irregular artic breakdowns',\n",
    "             'rapid rate',\n",
    "             'reduced OA loudness',\n",
    "             'abn pitch variability',\n",
    "             'strained',\n",
    "             'hypernasal',\n",
    "             'abn loudness variability',\n",
    "              'distortions']\n",
    "#set number of target classes for classification\n",
    "args.n_class = len(args.target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) check if output directory exists, SHOULD NOT BE A GS:// path\n",
    "if not os.path.exists(args.exp_dir):\n",
    "    os.makedirs(args.exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) check if PRETRAINED MDL is stored in gcs bucket\n",
    "if args.pretrained_mdl_path[:5] =='gs://':\n",
    "    pretrained_mdl_path = args.pretrained_mdl_path[5:].replace(args.bucket_name,'')[1:]\n",
    "    pretrained_mdl_path = download_model(pretrained_mdl_path, args.exp_dir, bucket)\n",
    "    args.pretrained_mdl_path = pretrained_mdl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) dump arguments\n",
    "args_path = \"%s/args.pkl\" % args.exp_dir\n",
    "with open(args_path, \"wb\") as f:\n",
    "    pickle.dump(args, f)\n",
    "#in case of error, everything is immediately uploaded to the bucket\n",
    "if args.cloud:\n",
    "    upload(args.cloud_dir, args_path, bucket)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an SSAST model\n",
    "\n",
    "We will start with only the finetuning option and not include the option for pretraining or only evaluating an already fine-tuned model (which is available in the full .py script)\n",
    "\n",
    "The data must be loaded in steps, starting by loading in the label data, then setting up audio configurations for training and evaluation, then generating AudioDataset objects, and finally setting up the dataloaders.\n",
    "\n",
    "When loading data, we start with a data split root, which we expect to be a directory containing a `train.csv` file and `test.csv` file with file names for train/test and the associated label data.\n",
    "\n",
    "The audio configurations are dictionaries with parameters for altering the audio and generating spectrograms.\n",
    "\n",
    "The AudioDatasets are set up in the `dataloader_mayo.py` script, using transforms specified in `utilities/speech_utils.py`. \n",
    "\n",
    "Finally, the dataloaders take in the datasets and batch size + number of workers.\n",
    "\n",
    "Please note that the resulting samples will be a dictionary with the keys `uid`, `fbank`, `waveform`, `targets`, `sample_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Load data, note that we are not doing any validation\n",
    "assert '.csv' not in args.data_split_root, f'May have given a full file path, please confirm this is a directory: {args.data_split_root}'\n",
    "train_df, val_df, test_df = load_data(args.data_split_root, args.exp_dir, args.cloud, args.cloud_dir, args.bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #(2) set audio configurations (val loader and eval loader will both use the eval_audio_conf\n",
    "train_audio_conf = {'dataset': args.dataset, 'mode': 'train', 'resample_rate': args.resample_rate, 'reduce': args.reduce, 'clip_length': args.clip_length,\n",
    "                'tshift':args.tshift, 'speed':args.speed, 'gauss_noise':args.gauss, 'pshift':args.pshift, 'pshiftn':args.pshiftn, 'gain':args.gain, 'stretch': args.stretch,\n",
    "                'num_mel_bins': args.num_mel_bins, 'target_length': args.target_length, 'freqm': args.freqm, 'timem': args.timem, 'mixup': args.mixup, 'noise':args.noise,\n",
    "                'mean':args.dataset_mean, 'std':args.dataset_std, 'skip_norm':args.skip_norm}\n",
    "\n",
    "eval_audio_conf = {'dataset': args.dataset, 'mode': 'evaluation', 'resample_rate': args.resample_rate, 'reduce': args.reduce, 'clip_length': args.clip_length,\n",
    "                'tshift':args.tshift, 'speed':args.speed, 'gauss_noise':args.gauss, 'pshift':args.pshift, 'pshiftn':args.pshiftn, 'gain':args.gain, 'stretch': args.stretch,\n",
    "                'num_mel_bins': args.num_mel_bins, 'target_length': args.target_length, 'freqm': args.freqm, 'timem': args.timem, 'mixup': args.mixup, 'noise':args.noise,\n",
    "                'mean':args.dataset_mean, 'std':args.dataset_std, 'skip_norm':args.skip_norm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3) Generate audio dataset, note that if bucket not given, it assumes None and loads from local files\n",
    "train_dataset = AudioDataset(annotations_df=train_df, target_labels=args.target_labels, audio_conf=train_audio_conf, \n",
    "                                prefix=args.prefix, bucket=args.bucket, librosa=args.lib) #librosa = True (might need to debug this one)\n",
    "val_dataset = AudioDataset(annotations_df=val_df, target_labels=args.target_labels, audio_conf=eval_audio_conf, \n",
    "                                prefix=args.prefix, bucket=args.bucket, librosa=args.lib) #librosa = True (might need to debug this one)\n",
    "eval_dataset = AudioDataset(annotations_df=test_df, target_labels=args.target_labels, audio_conf=eval_audio_conf, \n",
    "                            prefix=args.prefix, bucket=args.bucket, librosa=args.lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4) set up data loaders (val loader always has batchsize 1)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=args.num_workers, pin_memory=True, collate_fn=collate_fn)\n",
    "eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrograms\n",
    "We can now visualize a spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a spectrogram\n",
    "sample = train_loader.dataset[1]\n",
    "spectrogram = sample['fbank']\n",
    "label = sample['targets']\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(num=1, figsize=(15, 15), dpi=80)\n",
    "plt.imshow(spectrogram.transpose(1,0).flip(0))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model\n",
    "Set up the model using classes from `ast_models.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'pretrain' not in args.task, 'pretraining not supported in this notebook'\n",
    "ast_mdl = ASTModel_finetune(task=args.task, label_dim=args.n_class, \n",
    "                            fshape=args.fshape, tshape=args.tshape, \n",
    "                            fstride=args.fstride, tstride=args.tstride,\n",
    "                            input_fdim=args.num_mel_bins, input_tdim=args.target_length, \n",
    "                            model_size=args.model_size, load_pretrained_mdl_path=args.pretrained_mdl_path, \n",
    "                            activation='relu', final_dropout=0.2, layernorm=True, freeze=args.freeze, pooling_mode=args.pooling_mode)\n",
    "\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, ast_mdl.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f'Number of trainable parameters: {params}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training, evaluation, metrics\n",
    "\n",
    "Run the training loop, evaluate the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_train_loop(args, model, dataloader_train, dataloader_val = None):\n",
    "    \"\"\"\n",
    "    Training loop for finetuning SSAST \n",
    "    :param args: dict with all the argument values\n",
    "    :param model: SSAST model\n",
    "    :param dataloader_train: dataloader object with training data\n",
    "    :param dataloader_val: dataloader object with validation data\n",
    "    :return model: fine-tuned SSAST model\n",
    "    \"\"\"\n",
    "    print('Training start')\n",
    "    #send to gpu\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    #loss\n",
    "    if args.loss == 'MSE':\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    elif args.loss == 'BCE':\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        raise ValueError('MSE must be given for loss parameter')\n",
    "    #optimizer\n",
    "    if args.optim == 'adam':\n",
    "        optim = torch.optim.Adam([p for p in model.parameters() if p.requires_grad],lr=args.learning_rate)\n",
    "    elif args.optim == 'adamw':\n",
    "         optim = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=args.learning_rate)\n",
    "    else:\n",
    "        raise ValueError('adam must be given for optimizer parameter')\n",
    "    \n",
    "    if args.scheduler == 'onecycle':\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=args.max_lr, steps_per_epoch=len(dataloader_train), epochs=args.epochs)\n",
    "    else:\n",
    "        scheduler = None\n",
    "    \n",
    "    #train\n",
    "    for e in range(args.epochs):\n",
    "        training_loss = list()\n",
    "        #t0 = time.time()\n",
    "        model.train()\n",
    "        for batch in tqdm(dataloader_train):\n",
    "            x = batch['fbank']\n",
    "            targets = batch['targets']\n",
    "            x, targets = x.to(device), targets.to(device)\n",
    "            optim.zero_grad()\n",
    "            o = model(x)\n",
    "            loss = criterion(o, targets)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            loss_item = loss.item()\n",
    "            training_loss.append(loss_item)\n",
    "\n",
    "        if e % 10 == 0:\n",
    "            #SET UP LOGS\n",
    "            if scheduler is not None:\n",
    "                lr = scheduler.get_last_lr()\n",
    "            else:\n",
    "                lr = args.learning_rate\n",
    "            logs = {'epoch': e, 'optim':args.optim, 'loss_fn': args.loss, 'lr': lr}\n",
    "    \n",
    "            logs['training_loss_list'] = training_loss\n",
    "            training_loss = np.array(training_loss)\n",
    "            logs['running_loss'] = np.sum(training_loss)\n",
    "            logs['training_loss'] = np.mean(training_loss)\n",
    "\n",
    "            print('RUNNING LOSS', e, np.sum(training_loss) )\n",
    "            print(f'Training loss: {np.mean(training_loss)}')\n",
    "\n",
    "            if dataloader_val is not None:\n",
    "                print(\"Validation start\")\n",
    "                validation_loss = val_loop(model, criterion, dataloader_val)\n",
    "\n",
    "                logs['val_loss_list'] = validation_loss\n",
    "                validation_loss = np.array(validation_loss)\n",
    "                logs['val_running_loss'] = np.sum(validation_loss)\n",
    "                logs['val_loss'] = np.mean(validation_loss)\n",
    "                \n",
    "                print('RUNNING VALIDATION LOSS',e, np.sum(validation_loss) )\n",
    "                print(f'Validation loss: {np.mean(validation_loss)}')\n",
    "            \n",
    "            #SAVE LOGS\n",
    "            json_string = json.dumps(logs)\n",
    "            logs_path = os.path.join(args.exp_dir, 'logs_epoch{}.json'.format(e))\n",
    "            with open(logs_path, 'w') as outfile:\n",
    "                json.dump(json_string, outfile)\n",
    "            \n",
    "            #SAVE CURRENT MODEL\n",
    "            mdl_path = os.path.join(args.exp_dir, 'ast_mdl_epoch{}.pt'.format(e))\n",
    "            torch.save(model.state_dict(), mdl_path)\n",
    "            \n",
    "            if args.cloud:\n",
    "                upload(args.cloud_dir, logs_path, args.bucket)\n",
    "                #upload_from_memory(model.state_dict(), args.cloud_dir, mdl_path, args.bucket)\n",
    "                upload(args.cloud_dir, mdl_path, args.bucket)\n",
    "\n",
    "    print('Training finished')\n",
    "    mdl_path = os.path.join(args.exp_dir, '{}_{}_{}_{}_epoch{}_ast_mdl.pt'.format(args.dataset,args.model_size, args.n_class, args.optim, args.epochs))\n",
    "    torch.save(model.state_dict(), mdl_path)\n",
    "\n",
    "    if args.cloud:\n",
    "        upload(args.cloud_dir, mdl_path, args.bucket)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(model, criterion, dataloader_val):\n",
    "    '''\n",
    "    Validation loop for finetuning the w2v2 classification head. \n",
    "    :param model: W2V2 model\n",
    "    :param criterion: loss function\n",
    "    :param dataloader_val: dataloader object with validation data\n",
    "    :return validation_loss: list with validation loss for each batch\n",
    "    '''\n",
    "    validation_loss = list()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in tqdm(dataloader_val):\n",
    "            x = batch['fbank']\n",
    "            targets = batch['targets']\n",
    "            x, targets = x.to(device), targets.to(device)\n",
    "            o = model(x)\n",
    "            val_loss = criterion(o, targets)\n",
    "            validation_loss.append(val_loss.item())\n",
    "\n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(model, dataloader_eval, exp_dir, cloud=False, cloud_dir=None, bucket=None):\n",
    "    \"\"\"\n",
    "    Start model evaluation\n",
    "    :param model: SSAST model\n",
    "    :param dataloader_eval: dataloader object with evaluation data\n",
    "    :param exp_dir: specify LOCAL output directory as str\n",
    "    :param cloud: boolean to specify whether to save everything to google cloud storage\n",
    "    :param cloud_dir: if saving to the cloud, you can specify a specific place to save to in the CLOUD bucket\n",
    "    :param bucket: google cloud storage bucket object\n",
    "    :return preds: model predictions\n",
    "    :return targets: model targets (actual values)\n",
    "    \"\"\"\n",
    "    print('Evaluation start')\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    outputs = []\n",
    "    t = []\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in tqdm(dataloader_eval):\n",
    "            x = batch['fbank']\n",
    "            x = x.to(device)\n",
    "            targets = batch['targets']\n",
    "            targets = targets.to(device)\n",
    "            o = model(x)\n",
    "            outputs.append(o)\n",
    "            t.append(targets)\n",
    "\n",
    "    outputs = torch.cat(outputs).cpu().detach()\n",
    "    t = torch.cat(t).cpu().detach()\n",
    "    # SAVE PREDICTIONS AND TARGETS \n",
    "    pred_path = os.path.join(exp_dir, 'ast_eval_predictions.pt')\n",
    "    target_path = os.path.join(exp_dir, 'ast_eval_targets.pt')\n",
    "    torch.save(outputs, pred_path)\n",
    "    torch.save(t, target_path)\n",
    "\n",
    "    if cloud:\n",
    "        upload(cloud_dir, pred_path, bucket)\n",
    "        upload(cloud_dir, target_path, bucket)\n",
    "\n",
    "    print('Evaluation finished')\n",
    "    return outputs, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Now starting fine-tuning for {:d} epochs'.format(args.epochs))\n",
    "if not args.original_fn:\n",
    "    ast_mdl = finetune_train_loop(args, ast_mdl, train_loader, val_loader)\n",
    "else:\n",
    "    ast_mdl = train(args=args, audio_model=ast_mdl, train_loader=train_loader, val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(8) evaluation:\n",
    "if not args.original_fn:\n",
    "    preds, targets = eval_loop(ast_mdl, eval_loader, args.exp_dir, args.cloud, args.cloud_dir, args.bucket)\n",
    "    #aucs = metrics(args, preds, targets)\n",
    "else:\n",
    "    evaluation(args=args, audio_model=ast_mdl, eval_loader=eval_loader, val_loader=None) #TODO: does this need val dataloader????\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Embeddings\n",
    "\n",
    "Embedding extraction is a slightly different process. We instead load in one csv file, initialize and load a finetuned model, then run the embedding loop which extracts the last hidden layer 'pt' or the output of the first layer of the classification head 'ft' (which functions as the embedding of dim 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_split_root = 'gs://ml-e107-phi-shared-aif-us-p/speech_ai/share/data_splits/amr_subject_dedup_594_train_100_test_binarized_v20220620/test.csv'\n",
    "args.mode = 'extraction'\n",
    "args.embedding_type='ft' #if 'pt', it will get embeddings from only the pretrained model\n",
    "#args.mdl_path = None #TODO: must set to a finetuned model if you want it to load and get embeddings in that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # get original model args (or if no finetuned model, uses your original args)\n",
    "model_args, args.finetuned_mdl_path = setup_mdl_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) load data to get embeddings for\n",
    "assert '.csv' in args.data_split_root, f'A csv file is necessary for embedding extraction. Please make sure this is a full file path: {args.data_split_root}'\n",
    "annotations_df = pd.read_csv(args.data_split_root, index_col = 'uid')\n",
    "annotations_df[\"distortions\"]=((annotations_df[\"distorted Cs\"]+annotations_df[\"distorted V\"])>0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #(2) set audio configurations\n",
    "audio_conf = {'dataset': args.dataset, 'mode': 'evaluation', 'resample_rate': args.resample_rate, 'reduce': args.reduce, 'clip_length': args.clip_length,\n",
    "                'tshift':args.tshift, 'speed':args.speed, 'gauss_noise':args.gauss, 'pshift':args.pshift, 'pshiftn':args.pshiftn, 'gain':args.gain, 'stretch': args.stretch,\n",
    "                'num_mel_bins': args.num_mel_bins, 'target_length': args.target_length, 'freqm': args.freqm, 'timem': args.timem, 'mixup': args.mixup, 'noise':args.noise,\n",
    "                'mean':args.dataset_mean, 'std':args.dataset_std, 'skip_norm':args.skip_norm}\n",
    "\n",
    "# (3) set up dataloader with current args\n",
    "dataset = AudioDataset(annotations_df=annotations_df, target_labels=model_args.target_labels, audio_conf=audio_conf, \n",
    "                            prefix=args.prefix, bucket=args.bucket, librosa=args.lib)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, pin_memory=True, collate_fn=collate_fn) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_mdl = ASTModel_finetune(task=model_args.task, label_dim=model_args.n_class, \n",
    "                            fshape=model_args.fshape, tshape=model_args.tshape, \n",
    "                            fstride=model_args.fstride, tstride=model_args.tstride,\n",
    "                            input_fdim=model_args.num_mel_bins, input_tdim=model_args.target_length, \n",
    "                            model_size=model_args.model_size, load_pretrained_mdl_path=model_args.pretrained_mdl_path,\n",
    "                            activation='relu', final_dropout=0.2, layernorm=True, freeze=model_args.freeze, pooling_mode=model_args.pooling_mode)\n",
    "\n",
    "if args.finetuned_mdl_path is not None:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    sd = torch.load(args.finetuned_mdl_path, map_location=device)\n",
    "    ast_mdl.load_state_dict(sd, strict=False)\n",
    "else:\n",
    "    print(f'Extracting embeddings from only a pretrained model: {args.pretrained_mdl_path}. Extraction method changed to pt.')\n",
    "    args.embedding_type = 'pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_loop(model, dataloader, embedding_type='ft'):\n",
    "    \"\"\"\n",
    "    Run a specific subtype of evaluation for getting embeddings.\n",
    "    :param model: W2V2 model\n",
    "    :param dataloader_eval: dataloader object with data to get embeddings for\n",
    "    :param embedding_type: string specifying whether embeddings should be extracted from classification head (ft) or base pretrained model (pt)\n",
    "    :return embeddings: an np array containing the embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    print('Calculating Embeddings')\n",
    "    embeddings = np.array([])\n",
    "    # send to gpu\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in tqdm(dataloader):\n",
    "            x = batch['fbank']\n",
    "            x = x.to(device)\n",
    "            e = model.extract_embeddings(x, embedding_type)\n",
    "            if embeddings.size == 0:\n",
    "                embeddings = e\n",
    "            else:\n",
    "                embeddings = np.append(embeddings, e, axis=0)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_loop(ast_mdl, loader, args.embedding_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embed = pd.DataFrame([[r] for r in embeddings], columns = ['embedding'], index=annotations_df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if args.finetuned_mdl_path is not None:\n",
    "        args.finetuned_mdl_path = args.finetuned_mdl_path.replace(os.path.commonprefix([args.dataset, os.path.basename(args.finetuned_mdl_path)]), '')\n",
    "        pqt_path = '{}/{}_{}_{}_{}_embeddings.pqt'.format(args.exp_dir, args.dataset, os.path.basename(args.finetuned_mdl_path)[:-3], args.model_size, args.embedding_type)\n",
    "    else:\n",
    "        pqt_path = '{}/{}_ssast_{}_{}_embeddings.pqt'.format(args.exp_dir, args.dataset, args.model_size, args.embedding_type)\n",
    "    df_embed.to_parquet(path=pqt_path, index=True, engine='pyarrow') \n",
    "\n",
    "    if args.cloud:\n",
    "        upload(args.cloud_dir, pqt_path, args.bucket)\n",
    "except:\n",
    "    print('Unable to save as pqt, saving instead as csv')\n",
    "    if args.finetuned_mdl_path is not None:\n",
    "        args.finetuned_mdl_path = args.finetuned_mdl_path.replace(os.path.commonprefix([args.dataset, os.path.basename(args.finetuned_mdl_path)]), '')\n",
    "        csv_path = '{}/{}_{}_{}_{}_embeddings.csv'.format(args.exp_dir, args.dataset, os.path.basename(args.finetuned_mdl_path)[:-3], args.model_size, args.embedding_type)\n",
    "    else:\n",
    "        csv_path = '{}/{}_ssast_{}_{}_embeddings.csv'.format(args.exp_dir, args.dataset, args.model_size, args.embedding_type)\n",
    "    df_embed.to_csv(csv_path, index=True)\n",
    "\n",
    "    if args.cloud:\n",
    "        upload(args.cloud_dir, csv_path, args.bucket)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize AUC curves\n",
    "This hasn't been tested yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(args, preds, targets):\n",
    "    \"\"\"\n",
    "    Get AUC scores, doesn't return, just saves the metrics to a csv\n",
    "    :param args: dict with all the argument values\n",
    "    :param preds: model predictions\n",
    "    :param targets: model targets (actual values)\n",
    "    \"\"\"\n",
    "    #get AUC score and all data for ROC curve\n",
    "    metrics = {}\n",
    "    pred_mat=torch.sigmoid(preds).numpy()\n",
    "    target_mat=targets.numpy()\n",
    "    aucs=roc_auc_score(target_mat, pred_mat, average = None) #TODO: this doesn't work when there is an array with all labels as 0???\n",
    "    print(aucs)\n",
    "    data = pd.DataFrame({'Label':args.target_labels, 'AUC':aucs})\n",
    "    data.to_csv(os.path.join(args.exp_dir, 'aucs.csv'), index=False)\n",
    "    if args.cloud:\n",
    "        upload(args.cloud_dir, os.path.join(args.exp_dir, 'aucs.csv'), args.bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.basic:\n",
    "    for i in range(len(metrics[1])):\n",
    "        fpr, tpr, _ = roc_curve(metrics[2][:,i],  metrics[1][:,i])\n",
    "        plt.plot(fpr,tpr,label=metrics[0]['Label'][i]+\", auc=\"+str(round(metrics[0]['AUC'][i],3)))\n",
    "        plt.legend(loc=4)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
